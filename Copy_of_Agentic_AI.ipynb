{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEv1OPSS7S3Cr+IfQBhYDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saranrsaran/28seprepo/blob/master/Copy_of_Agentic_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xigVXikemBr"
      },
      "outputs": [],
      "source": [
        "## ðŸ“Œ Problem Statement\n",
        "\n",
        "We aim to simulate an autonomous agent that:\n",
        "- Starts in the middle of a 5-state environment\n",
        "- Learns by trial and error\n",
        "- Reaches a goal state using Q-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Environment Setup"
      ],
      "metadata": {
        "id": "37xjLnR3fm8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A simple linear environment with 5 states (0 to 4)\n",
        "class SimpleEnvironment:\n",
        "    def __init__(self):\n",
        "        self.states = [0, 1, 2, 3, 4]\n",
        "        self.current_state = 2\n",
        "        self.goal_state = 4\n",
        "        self.action_space = [0, 1]  # 0 = left, 1 = right\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_state = 2\n",
        "        return self.current_state\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            self.current_state = max(0, self.current_state - 1)\n",
        "        elif action == 1:\n",
        "            self.current_state = min(4, self.current_state + 1)\n",
        "\n",
        "        reward = 1 if self.current_state == self.goal_state else -0.1\n",
        "        done = self.current_state == self.goal_state\n",
        "        return self.current_state, reward, done"
      ],
      "metadata": {
        "id": "YtLxzaWxeo3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Q-Learning Agent"
      ],
      "metadata": {
        "id": "xWViLER5f6Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, state_size, action_size, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
        "        self.q_table = np.zeros((state_size, action_size))\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice([0, 1])\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state])\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        predict = self.q_table[state][action]\n",
        "        target = reward + self.gamma * np.max(self.q_table[next_state])\n",
        "        self.q_table[state][action] += self.alpha * (target - predict)"
      ],
      "metadata": {
        "id": "husoZTiPgA8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ‹ï¸ 3. Training the Agent"
      ],
      "metadata": {
        "id": "hagiPpp7gTx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(episodes=200):\n",
        "    env = SimpleEnvironment()\n",
        "    agent = QLearningAgent(state_size=5, action_size=2)\n",
        "    rewards_per_episode = []\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action = agent.choose_action(state)\n",
        "            next_state, reward, done = env.step(action)\n",
        "            agent.learn(state, action, reward, next_state)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        rewards_per_episode.append(total_reward)\n",
        "\n",
        "    return agent, rewards_per_episode"
      ],
      "metadata": {
        "id": "I8mKmIqQgYV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Demo the Agent"
      ],
      "metadata": {
        "id": "q9OdNdNYge3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_agent(agent):\n",
        "    env = SimpleEnvironment()\n",
        "    state = env.reset()\n",
        "    path = [state]\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        state, _, done = env.step(action)\n",
        "        path.append(state)\n",
        "\n",
        "    print(\"ðŸš€ Agent path to goal:\", path)"
      ],
      "metadata": {
        "id": "UEo0F7migkEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Run Training and Visualize Learning"
      ],
      "metadata": {
        "id": "_IN27iRqgorC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent, rewards = train_agent(episodes=200)\n",
        "\n",
        "# Show the path taken after training\n",
        "demo_agent(agent)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.plot(rewards)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"ðŸ“ˆ Agent Learning Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WQmdWhfMgt4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Code Implementation**"
      ],
      "metadata": {
        "id": "lht4kZZGhVty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python file (agentic_ai.py) now includes detailed comments, a well-structured Q-learning setup, and clean logic for training and demo.\n",
        "\n"
      ],
      "metadata": {
        "id": "o-nzw85yhZBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Model**\n",
        "\n",
        "\n",
        "A Q-learning model is used to help the agent learn the best action for each state.\n",
        "\n",
        "The Q-table is updated over 200 training episodes, learning from rewards and refining its decision-making."
      ],
      "metadata": {
        "id": "mlnK0DLWhcEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-N0TmZAShna7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "\n",
        "\n",
        "After training, the agent autonomously selects actions to reach the goal from the starting point (state 2).\n",
        "\n",
        "It prints the sequence of states visited and shows a learning curve (reward over episodes)."
      ],
      "metadata": {
        "id": "HAyScam-hww7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README (Brief Documentation)"
      ],
      "metadata": {
        "id": "TtDej9PHiYll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EK_C6qzOhhoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic AI: Simple Decision-Making Agent\n",
        "\n",
        "## ðŸ§© Problem Statement\n",
        "Create a basic agent that can make decisions and learn from its environment using reinforcement learning. The goal is for the agent to reach a predefined target state.\n",
        "\n",
        "## ðŸ”§ Approach\n",
        "- **Environment**: Linear 5-state world.\n",
        "- **Goal**: Move from state 2 to state 4.\n",
        "- **Agent**: Q-learning agent with:\n",
        "  - Exploration (epsilon-greedy)\n",
        "  - Reward-based learning\n",
        "- **Training**: 200 episodes to learn optimal actions.\n",
        "\n",
        "## ðŸš€ How to Run\n",
        "\n",
        "1. Install dependencies:\n",
        "   ```bash\n",
        "   pip install numpy , matplotlib"
      ],
      "metadata": {
        "id": "hbWiXhfOic2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the agent script:\n"
      ],
      "metadata": {
        "id": "xjEjztiXii9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bash\n",
        "\n",
        "python agentic_ai.py\n"
      ],
      "metadata": {
        "id": "FFVkgJ2ni4DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "Agent's path to reach the goal\n",
        "\n",
        "A plotted learning curve showing reward improvements"
      ],
      "metadata": {
        "id": "EhTp_CCOi7Y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Strategy\n",
        "\n",
        "Reward of +1 for reaching the goal\n",
        "\n",
        "Small penalty of -0.1 for other moves\n",
        "\n",
        "Q-values are updated to reflect better strategies"
      ],
      "metadata": {
        "id": "-U0n97Y9jA7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I3CW15gPjGKF"
      }
    }
  ]
}